{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc165a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5e2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40b00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv(\"./data/kc_house_data_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a60908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1d52a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c356bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    }
   ],
   "source": [
    "print(int(True), int(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75007d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['price_gt_1M'] = housing_df['price'].map(lambda x: int(x >= 1000000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7615b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21613 non-null  float64\n",
      " 1   bedrooms       21613 non-null  int64  \n",
      " 2   bathrooms      21613 non-null  float64\n",
      " 3   sqft_living    21613 non-null  int64  \n",
      " 4   sqft_lot       21613 non-null  int64  \n",
      " 5   floors         21613 non-null  float64\n",
      " 6   waterfront     21613 non-null  int64  \n",
      " 7   view           21613 non-null  int64  \n",
      " 8   condition      21613 non-null  int64  \n",
      " 9   grade          21613 non-null  int64  \n",
      " 10  sqft_above     21613 non-null  int64  \n",
      " 11  sqft_basement  21613 non-null  int64  \n",
      " 12  yr_built       21613 non-null  int64  \n",
      " 13  yr_renovated   21613 non-null  int64  \n",
      " 14  zipcode        21613 non-null  int64  \n",
      " 15  lat            21613 non-null  float64\n",
      " 16  long           21613 non-null  float64\n",
      " 17  sqft_living15  21613 non-null  int64  \n",
      " 18  sqft_lot15     21613 non-null  int64  \n",
      " 19  price_gt_1M    21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "housing_df = housing_df.iloc[:, 2:]\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef21cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcols_class = [_ for _ in range(1, 20)]\n",
    "newcols_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86bc0b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcols_regression = [_ for _ in range(1, 18)]\n",
    "newcols_regression.extend([0])\n",
    "newcols_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6b1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       21613 non-null  int64  \n",
      " 1   bathrooms      21613 non-null  float64\n",
      " 2   sqft_living    21613 non-null  int64  \n",
      " 3   sqft_lot       21613 non-null  int64  \n",
      " 4   floors         21613 non-null  float64\n",
      " 5   waterfront     21613 non-null  int64  \n",
      " 6   view           21613 non-null  int64  \n",
      " 7   condition      21613 non-null  int64  \n",
      " 8   grade          21613 non-null  int64  \n",
      " 9   sqft_above     21613 non-null  int64  \n",
      " 10  sqft_basement  21613 non-null  int64  \n",
      " 11  yr_built       21613 non-null  int64  \n",
      " 12  yr_renovated   21613 non-null  int64  \n",
      " 13  zipcode        21613 non-null  int64  \n",
      " 14  lat            21613 non-null  float64\n",
      " 15  long           21613 non-null  float64\n",
      " 16  sqft_living15  21613 non-null  int64  \n",
      " 17  sqft_lot15     21613 non-null  int64  \n",
      " 18  price_gt_1M    21613 non-null  int64  \n",
      "dtypes: float64(4), int64(15)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "housing_class_df = housing_df.iloc[:, newcols_class]\n",
    "housing_class_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afcaf96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   bedrooms       21613 non-null  int64  \n",
      " 1   bathrooms      21613 non-null  float64\n",
      " 2   sqft_living    21613 non-null  int64  \n",
      " 3   sqft_lot       21613 non-null  int64  \n",
      " 4   floors         21613 non-null  float64\n",
      " 5   waterfront     21613 non-null  int64  \n",
      " 6   view           21613 non-null  int64  \n",
      " 7   condition      21613 non-null  int64  \n",
      " 8   grade          21613 non-null  int64  \n",
      " 9   sqft_above     21613 non-null  int64  \n",
      " 10  sqft_basement  21613 non-null  int64  \n",
      " 11  yr_built       21613 non-null  int64  \n",
      " 12  yr_renovated   21613 non-null  int64  \n",
      " 13  zipcode        21613 non-null  int64  \n",
      " 14  lat            21613 non-null  float64\n",
      " 15  long           21613 non-null  float64\n",
      " 16  sqft_living15  21613 non-null  int64  \n",
      " 17  price          21613 non-null  float64\n",
      "dtypes: float64(5), int64(13)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "housing_regression_df = housing_df.iloc[:, newcols_regression]\n",
    "housing_regression_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29aaf74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_class_df.to_csv(\"./data/kc_house_data_classification.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd42c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_regression_df.to_csv(\"./data/kc_house_data_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d4b85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Categorize Feature Types\n",
    "\n",
    "categorical_features = ['waterfront', 'view', 'condition', 'grade', 'zipcode']\n",
    "numerical_features = [col for col in housing_df.columns if col not in categorical_features + ['price_gt_1M']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "649cfb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17290, 19)\n",
      "X_test shape: (4323, 19)\n",
      "y_train shape: (17290,)\n",
      "y_test shape: (4323,)\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Train-Test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = housing_df.drop(columns=['price_gt_1M'])\n",
    "y = housing_df['price_gt_1M']\n",
    "\n",
    "#  train_test_split function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=73)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d30550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null model training accuracy: 0.933\n",
      "Null model test accuracy: 0.924\n",
      "Training Confusion Matrix:\n",
      " [[16127     0]\n",
      " [ 1163     0]]\n",
      "Test Confusion Matrix:\n",
      " [[3994    0]\n",
      " [ 329    0]]\n"
     ]
    }
   ],
   "source": [
    "# Define logistic regression model\n",
    "\n",
    "# Model 0: The null model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Null model\n",
    "null_model = DummyClassifier(strategy='most_frequent')\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = null_model.predict(X_train)\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Null model training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Null model test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3328c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression training accuracy: 0.998\n",
      "Ridge Regression test accuracy: 0.995\n",
      "Training Confusion Matrix:\n",
      " [[16115    12]\n",
      " [   31  1132]]\n",
      "Test Confusion Matrix:\n",
      " [[3992    2]\n",
      " [  21  308]]\n"
     ]
    }
   ],
   "source": [
    "#Model 1: Ridge Regression with C=1.0\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Ridge regression model\n",
    "ridge_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, penalty='l2', solver='saga', max_iter=2000))\n",
    "])\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = ridge_model.predict(X_train)\n",
    "y_test_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Ridge Regression training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Ridge Regression test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d903d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression training accuracy: 0.999\n",
      "Lasso Regression test accuracy: 0.997\n",
      "Training Confusion Matrix:\n",
      " [[16124     3]\n",
      " [   22  1141]]\n",
      "Test Confusion Matrix:\n",
      " [[3993    1]\n",
      " [  13  316]]\n"
     ]
    }
   ],
   "source": [
    "#Model 2: Lasso Regression with C=1.0\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Lasso regression model\n",
    "lasso_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, penalty='l1', solver='saga', max_iter=5000))\n",
    "])\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "y_test_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Lasso Regression training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Lasso Regression test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "046c6c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression (C=0.01) training accuracy: 0.991\n",
      "Lasso Regression (C=0.01) test accuracy: 0.989\n",
      "Training Confusion Matrix:\n",
      " [[16127     0]\n",
      " [  158  1005]]\n",
      "Test Confusion Matrix:\n",
      " [[3994    0]\n",
      " [  47  282]]\n"
     ]
    }
   ],
   "source": [
    "#Model 3: Lasso Regression with C=0.01\n",
    "\n",
    "# Lasso regression model with C=0.01\n",
    "\n",
    "lasso_model_001 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=0.01, penalty='l1', solver='saga', max_iter=5000))\n",
    "])\n",
    "\n",
    "\n",
    "lasso_model_001.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = lasso_model_001.predict(X_train)\n",
    "y_test_pred = lasso_model_001.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Lasso Regression (C=0.01) training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Lasso Regression (C=0.01) test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5cbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 4: Lasso Regression with Optimal C\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Lasso regression with cross-validated optimal C\n",
    "lasso_cv_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegressionCV(Cs=10, cv=5, penalty='l1', solver='saga', max_iter=5000))\n",
    "])\n",
    "\n",
    "lasso_cv_model.fit(X_train, y_train)\n",
    "\n",
    "# Optimal C\n",
    "optimal_C = lasso_cv_model.named_steps['classifier'].C_[0]\n",
    "print(f'Optimal C value: {optimal_C}')\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = lasso_cv_model.predict(X_train)\n",
    "y_test_pred = lasso_cv_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Lasso Regression CV training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Lasso Regression CV test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1436ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 5 \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Decision tree model\n",
    "tree_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=73))\n",
    "])\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = tree_model.predict(X_train)\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Decision Tree training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Decision Tree test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy score, create a confusion matrix, and discuss the performance relative to your logistic regression models\n",
    "\n",
    "# Compute accuracy scores for both training and test sets\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print accuracy scores\n",
    "print(f'Decision Tree training accuracy: {train_accuracy:.3f}')\n",
    "print(f'Decision Tree test accuracy: {test_accuracy:.3f}')\n",
    "\n",
    "# Create confusion matrices\n",
    "train_conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "test_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print confusion matrices\n",
    "print('Training Confusion Matrix:\\n', train_conf_matrix)\n",
    "print('Test Confusion Matrix:\\n', test_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806e130",
   "metadata": {},
   "source": [
    "*discussion-\n",
    "When comparing the decision tree model to the logistic regression models (both Ridge and Lasso), consider the following:\n",
    "\n",
    "Accuracy Scores - Higher accuracy on the training set often indicates that the decision tree may be overfitting. Overfitting is when the model performs well on training data but poorly on test data.\n",
    "Confusion Matrices: These provide more detailed insights into the types of errors being made, which is crucial for understanding model performance beyond just accuracy.\n",
    "Decision trees are flexible models that can capture complex patterns in the data but are also prone to overfitting. This is in contrast to logistic regression models, which are less flexible and thus less likely to overfit, especially with regularization (Ridge and Lasso).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aec1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'decision_tree' is previously defined and fitted\n",
    "decision_tree = tree_model\n",
    "\n",
    "# Get feature names for the categorical variables after one-hot encoding\n",
    "onehot_feature_names = decision_tree.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine numerical feature names with the expanded categorical feature names\n",
    "all_feature_names = numerical_features + onehot_feature_names.tolist()\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(decision_tree.named_steps['classifier'], filled=True, feature_names=all_feature_names, class_names=['<=1M', '>1M'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28df3db",
   "metadata": {},
   "source": [
    "*We don't need to create a coefficient plot for decision trees because decision trees do not have coefficients like linear models (e.g., logistic regression). In logistic regression, the coefficients represent the contribution of each feature to the predicted outcome, and visualizing them helps understand which features are more influential in the model's decision-making process.\n",
    "\n",
    "However, decision trees make splits in the feature space based on threshold values, rather than coefficients. Therefore, visualizing a decision tree typically involves plotting the tree structure itself to understand how the features are used to make decisions at each node. This visualization provides insights into the decision-making process of the tree model, rather than coefficients representing feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202c6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Define and fit the Lasso model\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "lasso_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=1.0, penalty='l1', solver='saga', max_iter=5000))\n",
    "])\n",
    "\n",
    "# Assuming 'X_train' and 'y_train' are already defined\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "lasso_predictions = lasso_model.predict(X_test)\n",
    "\n",
    "# Convert lasso_predictions to a pandas Series\n",
    "lasso_predictions = pd.Series(lasso_predictions, index=X_test.index)\n",
    "\n",
    "# Load the original test data\n",
    "test_data = pd.read_csv(\"./data/kc_house_data_classification.csv\")\n",
    "\n",
    "# Load the regression dataset to get the actual prices\n",
    "regression_data = pd.read_csv(\"./data/kc_house_data_regression.csv\")\n",
    "\n",
    "# Extract the test indices used in the train-test split\n",
    "test_indices = X_test.index\n",
    "\n",
    "# Filter the test_data and regression_data using the test indices\n",
    "test_data = test_data.loc[test_indices]\n",
    "regression_data = regression_data.loc[test_indices]\n",
    "\n",
    "# Join the regression dataset with the test data based on the index\n",
    "merged_data = test_data.join(regression_data.set_index(test_data.index), rsuffix='_regression')\n",
    "\n",
    "# Ensure the indices are properly aligned\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "lasso_predictions = lasso_predictions.reset_index(drop=True)\n",
    "merged_data = merged_data.reset_index(drop=True)\n",
    "\n",
    "# Extract the actual prices for the rows where the predictions were incorrect\n",
    "incorrect_predictions = merged_data.loc[lasso_predictions != y_test]\n",
    "incorrect_prices = incorrect_predictions['price']\n",
    "\n",
    "# Plot a histogram of the actual prices for the incorrect predictions\n",
    "plt.hist(incorrect_prices, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Actual Prices for Incorrect Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e9c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacker Extra\n",
    "# Part 1 - Histogram-based Gradient Boosting Classifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "classification_df = pd.read_csv('./data/kc_house_data_classification.csv')\n",
    "\n",
    "# Define features and target\n",
    "categorical_features = ['waterfront', 'view', 'condition', 'grade', 'zipcode']\n",
    "numeric_features = [col for col in classification_df.columns if col not in categorical_features + ['price_gt_1M']]\n",
    "X = classification_df.drop(columns='price_gt_1M')\n",
    "y = classification_df['price_gt_1M']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=73)\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Histogram-based Gradient Boosting model pipeline\n",
    "hgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', HistGradientBoostingClassifier(random_state=73))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "hgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = hgb_pipeline.predict(X_train)\n",
    "y_test_pred = hgb_pipeline.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "print(f'Histogram-based Gradient Boosting training accuracy: {accuracy_score(y_train, y_train_pred):.3f}')\n",
    "print(f'Histogram-based Gradient Boosting test accuracy: {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "\n",
    "# Confusion matrices\n",
    "print('Training Confusion Matrix:\\n', confusion_matrix(y_train, y_train_pred))\n",
    "print('Test Confusion Matrix:\\n', confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(confusion_matrix(y_test, y_test_pred), interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = [0, 1]\n",
    "plt.xticks(tick_marks, ['<=1M', '>1M'], rotation=0)\n",
    "plt.yticks(tick_marks, ['<=1M', '>1M'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part-2 Lasso Regression for Price Prediction\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Load the dataset\n",
    "housing_df_reg = pd.read_csv('./data/kc_house_data_regression.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = housing_df_reg.drop('price', axis=1)\n",
    "y = housing_df_reg['price']\n",
    "\n",
    "# Preprocessing and LassoCV\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        ('cat', OneHotEncoder(), X.select_dtypes(include=['object']).columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "lasso_cv_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LassoCV(cv=5))\n",
    "])\n",
    "\n",
    "lasso_cv_model.fit(X, y)\n",
    "\n",
    "# Optimal alpha\n",
    "optimal_alpha = lasso_cv_model.named_steps['regressor'].alpha_\n",
    "print(f'Optimal alpha value: {optimal_alpha}')\n",
    "\n",
    "# Predictions\n",
    "y_pred = lasso_cv_model.predict(X)\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
